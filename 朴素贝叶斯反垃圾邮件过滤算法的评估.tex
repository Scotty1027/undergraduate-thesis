\documentclass[UTF8]{ctexart}
\usepackage{geometry}
\geometry{a4paper,scale=0.8}
\title{朴素贝叶斯反垃圾邮件过滤算法的评估}
\author{Ion Androutsopoulos\\ Konstantinos V. Chandrinos\\George Paliouras
	and Constantine D. Spyropoulos}
\date{}
\begin{document}
\maketitle
\begin{abstract}
最近有许多关于朴素贝叶斯分类器是否可用于过滤来路不明的群发电子邮件（“垃圾邮件”）的争论。 我们对我们公开提供的语料库对此提案进行了全面评估，为标准基准做出了贡献。 同时，我们研究了属性集大小、训练语料库大小、词形还原和禁用词表对过滤器性能的影响，在此之前这些问题从来都没有被别人研究过。 在引入适当的 cost-sensitive 评估措施后，我们得出的结论是，朴素贝叶斯反垃圾邮件过滤器需要额外的安全网才能做到实际可行。	
\end{abstract}

\section{简介}
盲目地群发垃圾邮件这一现象正在变得越来越普遍。 尽管大多数用户发现后会立即删除这些令人厌恶的垃圾邮件，其低成本的特性还是直接导致了营销广告的盛行。 1997年的一项研究（Cranor＆LaMacchia，1998）显示发送至公司网络的电子邮件中有10\%是垃圾邮件。 除了浪费时间外，垃圾邮件还会浪费带宽，从而给用户造成经济损失，并且有可能会使未成年的收件人暴露在不合适的内容（如 色情）中。 

市面上已经有一些垃圾邮件过滤器可供获取。  它们主要依靠人工构建的模式匹配规则，需要调整到适合每个用户收到的消息，同时也需要一定时间和专业知识。 此外，垃圾邮件的特征（例如，给商品打广告，频繁出现的术语）也会随着时间的推移而发生变化，这也要求了对规则的日常维护。 因此一个可以自动学习并识别垃圾邮件的系统将具有显著的优势。

几种机器学习算法已应用到了文本分类领域（例如Apte＆Damerau， 1994; 刘易斯，1996年; Dagan等，1997; 见塞巴斯蒂安尼，1999年的一项调查）。 这些算法先在一些已经人工分好类的文档上学习后，根据文档内容将未分类的文档分类为固定类别。这种算法也被用于线程电子邮件（Lewis＆ Knowles，1997），自动分类电子邮件（Cohen，1996; Payne＆Edwards，1997），识别有趣的新闻文章（Lang，1995）等。然而据我们所知，只有一次曾经有人尝试将机器学习算法应用于垃圾邮件过滤领域（Sahami et al。，1998）。 

Sahami等人在经由人工分类的合法邮件和垃圾邮件的基础上训练了一个朴素贝叶斯分类器（Duda＆Hart，1973; Mitchell 1997） ，它在新消息的分类上展现出了令人印象深刻的准确率和召回率。 令人惊讶的是，文本分类在反垃圾邮件过滤领域是十分有效的：不像其他文本分类任务，是盲目群发使得垃圾邮件成为垃圾邮件，而不是其实际内容。 然而，垃圾邮件的语言似乎构成了一种独特的类型，并且垃圾邮件提及关于合法邮件中很少提及的主题，这使得训练一个用于反垃圾邮件过滤的文本分类器这一目的具有了可能性。

文本分类研究受益于公开的经过手动分类的文档集合，如已被当做基准的路透社语料库（Lewis，1992）。 创造用于反垃圾邮件过滤研究的类似的资源并不是一件简单的事情，因为用户接收的电子邮件流不可能在不侵犯他/她的隐私的前提下公开。但是，可以通过混淆垃圾邮件和无垃圾邮件的公共档案中提取的邮件，以得到一个近似于普通用户收的邮件列表。遵循着这个方向，我们在垃圾邮件和通过Linguist list（一个关于该专业的（因此，无垃圾邮件）专业语言学列表）发送的消息的混合体上测试了Sahami的方法。 由此产生的语料库被称为Ling-Spam，可供其他人公开访问、用作基准。 

当然，Linguist消息比大多数用户接受的电子邮件更加特定于某一些主题。 然而他们的标准化程度低于人们的预期（例如，它们包含了职位发布，软件可用性公告，甚至是火焰般的回复），在一定程度上，可以通过Ling-Spam得到用户传入的电子邮件在关于反垃圾邮件的过滤上是有用的初步结论，至少在一个更好的语料库被公布前。通过更直接的解释，我们的实验可以看作是一项研究用于开放的未经审核的邮件列表或新闻组的反垃圾邮件过滤器。 

与Sahami等人不同，我们使用十倍交叉验证，这使我们的结果不易产生随机变化。 我们的实验还通过调查属性集大小，训练语料库大小，词形还原和禁用词表对问题的影响，以及 Sahami等人的研究未涵盖的方面，揭示了朴素贝叶斯反垃圾邮件过滤的行为。 此外，我们展示了如何将采用决策理论的成本概念纳入评估措施 。 我们的结果证实了Sahami等人的研究的高准确率和回归率。 然而，cost-sensitive 的评估表明朴素贝叶斯过滤器需要一个互补的安全网，然后才是可行的。

第2节讨论了朴素贝叶斯分类; 第3节列出了Sahami等人的结果; 第4节 描述了我们的过滤系统、Ling-Spam语料库和我们得到的结果; 第5节介绍了cost-sensitive评估措施; 第6节总结。

\section{朴素贝叶斯分类}
每条消息都由一个向量x表示，x1...xn 是的属性 X1...Xn 的值。跟随Sahami等人的脚步，我们使用二元属性： Xi=1 代表消息中存在X; 否则Xi = 0。在我们的实验中，属性对应于单词，即每个属性显示是否存在特定单词（例如“成人”）。 为了在所有可能的属性中挑选出，我们遵循Sahami等人的方法，通过每个候选属性 X 和分类表达变量 C 来计算相互信息（ MI ）。
$$M I(X;C)=\sum_{x \in\{0,1\}, c \in\{spam, legitimate\}} P(X=x, C=c) \cdot \log \frac{P(X=x, C=c)}{P(X=x) \cdot P(C=c)}$$

选择具有最高 MI的属性 。 概率估计为培训语料库的频率比（参见Mitchell，1996，我们计划将来纳入更好的估算器）。

根据贝叶斯定理和总概率定理，给出了一个文档 d 向量 x ， d 可被归为 c 类的概率是
$$P(C=c | \vec{X}=\vec{x})=\frac{P(C=c) \cdot P(\vec{X}=\vec{x} | C=c)}{\sum_{k \in\{spam,legitimate\}} P(C=k) \cdot P(\vec{X}=\vec{x} | C=k)}$$

P(X|C)实际上不可能直接估算（X的可能值有许多，并且存在数据稀疏问题）。朴素贝叶斯分类器简化地假设了 X1...Xn  有条件独立于C类，。 然后：

$$P(C=c | \vec{X}=\vec{x})=\frac{P(C=c) \cdot \prod_{i=1}^{n} P\left(X_{i}=x_{i} | C=c\right)}{\sum_{k \in \{s p a m , l e g i t i m a t e \}} P(C=k) \cdot \prod_{i=1}^{n} P\left(X_{i}=x_{i} | C=k\right)}$$ 

P(Xi|C)和P(C)可以很容易地被估计为来自训练语料库的相对频率。 一些研究发现朴素贝叶斯分类器具有惊人的效果（Langley等， 1992; Domingos＆Pazzani，1996），尽管其独立性假设通常过于简单。 

错误地阻止合法邮件（将​​其归类为垃圾邮件）通常比让垃圾邮件通过过滤器（将垃圾邮件分类为合法邮件）更为严重。 让 L→S 和 S→L 表示两种错误类型。 假如说 L→S 是$\lambda$倍于S→L，如果满足以下条件，我们就将消息分类为垃圾邮件。

$$\frac{P(C=spam | \vec{X}=\vec{x})}{P(C= legitimate | \vec{X}=\vec{x})}>\lambda$$

在某种程度上独立性假设是成立的，并且概率估计是准确的，则 a 分类采用这一标准可以达到最佳效果（Duda＆Hart，1973）。 在我们的例子中，$P(C=spam | \vec{X}=\vec{x})=1-P(C=$legitimate$| \vec{X}=\vec{x})$，也引出了这个标准的变体：

$$P(C=spam | \vec{X}=\vec{x})>t, with\ t=\frac{\lambda}{1+\lambda}, \lambda=\frac{t}{1-t}$$

Sahami等人将阈值t设置为0.999（ $\lambda=999$ ）; 即阻止合法的消息通过跟让999封垃圾邮件通过过滤器一样严重。 当阻塞消息且不进行更多的处理时，如此高的 $\lambda$ 值是合理的，因为大多数用户会认为丢失合法的消息是不可接受的。 然而，替代配置是可能的，其中较低的 $\lambda$ 值是合理的。可以通过将邮件返回给发件人，将其重新发送到收件人的私人电子邮件地址，而不是删除被阻止的邮件（另见Hall，1998）。私人的地址永远不会被广告（例如在网页上）打扰，因此不太可能直接收到垃圾邮件；和重新发送的请求可能包括一个经常变化的谜语（例如“包括在主题中的法国首都。“）以确保邮件回复并不是由垃圾邮件生成机器人发送。 在这种情况下，  $\lambda=9$ （ t=9 ） 似乎是合理的：阻止合法邮件比通过垃圾邮件更容易受到惩罚，以模拟重新发送被阻止的消息要比手动删除垃圾邮件涉及更多工作。 甚至 $ \lambda=1$ （ t=0.5 ）也是可接受的，如果收件人不关心发件人的额外工作。

\section{先前的结果}
表1总结了Sahami等人的结果。 如果 nL → S 和  nS→L λ是 L →S 和 S → L的错误数目， nL→ L 和 n S→ S，是正确处理的合法和垃圾邮件的数量，那么是垃圾邮件召回率（SR）和垃圾邮件准确率（SP）是：$$S R=\frac{n_{S \rightarrow S}}{n_{S \rightarrow S}+n_{S \rightarrow L}} \quad S P=\frac{n_{S \rightarrow S}}{n_{S \rightarrow S}+n_{L \rightarrow S}}$$

在表1的第二个实验中，候选属性不仅包括单词属性，还包括显示特定的人工选择的短语（例如“超过21”）是否存在的属性。 在第三和第四个实验，添加了非文本候选属性，显示消息是否有手动选择的属性（例如附件）。 Sahami等人的短语和非文本属性引入了一个 手动配置阶段，因为必须手动选择哪些短语和非文本特征要被视为候选属性。由于我们的目标是探索全自动反垃圾邮件过滤，我们限制自己仅仅使用单词属性。

\section{使用 Ling-Spam 进行的实验}
我们的实验都是在Ling-Spam语料库上进行的，其中包括：

• 通过从档案中随机下载摘要获得的2412条 Linguist 消息，分离他们的消息，并删除列表服务器添加的文本。

• 第一作者收到的481封垃圾邮件。 附件，HTML标记和同一天收到的重复的垃圾邮件不包括在内。

垃圾邮件是语料库的16.6％，这个数字接近作者的垃圾邮件率、Sahami等人的第四个实验得到的结果比率和其他地方新闻报道的比率（Cranor＆LaMacchia，1998）。
我们的朴素贝叶斯过滤器实现（在GATE上开发）包括一个将每个单词转换为其基本形式的变形器，以及一个禁用词表，以从消息中删除的英国国家语料库（BNC）给出的100个最常用的词。可以启用或禁用两个模块来衡量他们的影响。

为了减少随机变化，采用十倍交叉验证，并报告平均分数。 在第一系列实验中，保留属性（最高MI）的数量范围为50至700（步长50），对应启用/禁用的变形器和禁用词表的所有组合。 我们尝试了三个阈值： t=999.0  （ $\lambda=999 $） t=0.9 （ $\lambda=9$ ），和 t=0.5 （$\lambda=1$ ）。 如第2节所述，这些代表 三种情况：删除被阻止的消息; 重发请求并核算发件人的额外工作; 和发出重发请求，忽略发件人的额外工作。

图1-3显示过滤器在所有三个阈值都展现了令人印象深刻的垃圾邮件召回率和准确率，也验证了Sahami等人的研究结果。在所有情况下，词形还原似乎都会改善结果。 $\lambda=1$ 和  $\lambda=9$的禁用词表对此有积极作用 ，但 $\lambda =999$ 的效果看起来可以忽略不计。但是，如果没有单一的评估指标来代替垃圾邮件的准确率和召回率，很难检查词形变换器和禁用词表的影响是否具有统计意义。

对于$ \lambda=999$，阻止合法邮件比让垃圾邮件通过过滤更严重。因此，我们假设是最大化垃圾邮件精度的配置才是“最佳”配置。这是通过300个属性和启用的变形器实现的（100％垃圾邮件准确率，63\% 垃圾召回率; 在这里，禁用词表的效果可以忽略不计）。但是对于 $\lambda=1$ 和 $\lambda=9$，很难说哪种配置（精确和召回的组合）是最好的。 同样，一个衡量标准是需要; 它必须对我们的成本敏感。 我们接下来讨论这个。

\section{成本敏感的评估措施}
在分类任务中，两种常用的评估措施是准确度（Acc）和错误率 （ Err = 1 - Acc ）。 在我们的情况下：$$Acc=\frac{n_{L \rightarrow L}+n_{S \rightarrow S}}{N_{L}+N_{S}} \quad E r r=\frac{n_{L \rightarrow S}+n_{S \rightarrow L}}{N_{L}+N_{S}}$$

NL和NS是要分类的合法和垃圾邮件的数量。

准确度和错误率为两种错误类型分配相同的权重（ L → S和  S → L）。 然而，当选择分类器的阈值（第2节）时，我们假设  L → S是 S → L 的$\lambda$倍。 为了使准确率和错误率对此成本敏感，我们将每一个合法的消息视作 $\lambda$消息：当合法消息被错误分类时，这被视为$\lambda$错误; 当它被正确分类时，这算作$ \lambda$成功。 由此引出了加权精度（WAcc） 和加权错误率（WErr = 1 - WAcc ）：$$W A c c=\frac{\lambda \cdot n_{L \rightarrow L}+n_{S \rightarrow S}}{\lambda \cdot N_{L}+N_{S}} \quad W E r r=\frac{\lambda \cdot n_{L \rightarrow S}+n_{S \rightarrow L}}{\lambda \cdot N_{L}+N_{S}}$$

当使用准确度或错误率（加权与否）时，与简单比较 “基线”方法是很重要的，为避免误解，通常设置高准确度和低错误率。 如基线，我们使用不存在过滤器的假设：合法消息（正确）从不被阻止， 和垃圾邮件（错误地）总是通过过滤器。 加权精度和误差率基线是：$$WAcc^{b}=\frac{\lambda \cdot N_{L}}{\lambda \cdot N_{L}+N_{S}} \quad W E r r^{b}=\frac{N_{S}}{\lambda \cdot N_{L}+N_{S}}$$

为了简单地与基准比较，我们引入了总成本率：$$TCR=\frac{W E r r^{b}}{W E r r}=\frac{N_{S}}{\lambda \cdot n_{L \rightarrow S}+n_{S \rightarrow L}}$$

TCR 越高性能越好。 对于 TCR < 1，不使用过滤器更好。 当成本与浪费的时间成比例时， TCR测量了在没有过滤器的情况下多少时间被浪费在手动删除垃圾邮件上，然后与手动删除垃圾邮件浪费的时间加上恢复错误阻止的合法讯息所需的时间作比较。

表2列出了垃圾邮件召回率，垃圾邮件准确率，加权准确度，基线加权准确度和 TCR ，过滤器的各种配置，以及导致最高 TCR 的配置的属性。图4-6显示了不同数量的属性的TCR  $\lambda=1,9,999$。所有的用例中都使用了十倍交叉验证，并报告平均 WAcc 。 TCR计算为  WErrb 除以平均值 WErr 。 增加超出某一特定点的属性数量通常会降低性能，因为低 MI 的属性不能很好地区分两类。

在所有三个$ \lambda$值下，在启用了变形器的情况下获得了最高的TCR分数。 $\lambda=1$和$\lambda=9$的禁用词表具有额外的积极影响，除了$\lambda=999$ 。 然而，差异并不总是具有统计意义。 对于 $\lambda=1$ ，在所有过滤器的配置的WAcc上进行成对的单尾t检验 表2的仅仅显示配置（b）和（d）优于（a），p<0.05 。 然而，所有四种配置明显优于基线。对于$\lambda=9$，没有任何表2的假设，例如配置（d）优于（a），在统计上显着  p<0.05 ，但 p<0.01 时所有配置明显优于基线。 对于 $\lambda=999$ ，只有启用了变形器后过滤器才到达了 TCR>1 。禁用词表基本上没有效果，并且 p<0.01 时配置（c）和（d）都明显优于基线。 

总的来说，$\lambda=1$ 和 $\lambda=9$时过滤器表现出稳定的行为， TCR不断增大且大于1。然而$ \lambda=999$ 时，过滤器仅在启用了特定数量的属性 （300）时才实现了 TCR>1 ，因为 L→ S错误被严重惩罚，以至于单个被阻止的合法消息足够  WAccb 超过 WAcc （过滤器在300个属性中没有出现此类错误）。 在真实的应用程序中，不太可能精确地确定最佳属性数， 这使得我们对$\lambda=999$过滤器的适用性产生怀疑。

更令人担忧的是 $\lambda=999$ ，这是我们进行的第二系列实验的结果，这次我们改变了训练语料库的大小。每重复十次，将Ling-Spam分成两部分，其中一个部分保留用于测试。剩余九个部分中的每一部分，只有 x％ 用于训练， x范围从10到100乘以10。图7显示了得到的TCR分数。所有实验都是在启用了变形器和禁用词表的情况下进行的，并且伴随着最佳数量的属性，如表2所示。

不像 $\lambda=1$ 和 $\lambda=9$ ，$\lambda=999$ 过滤器仅在100％的训练语料库的前提下到达了 TCR>1， 我们不能轻易地认为在接受了更多的训练后 TCR 仍会保持>1。 （我们归因于最初的 TCR 的最高点是 ，在很少训练的情况下，分类器倾向于将所有消息分类为 最常见的类别，即合法，保护它免于 L→ S错误）。 这些 研究结果表明在 $\lambda=999$时 ，过滤器的使用是不足够安全的。

\section{结论}
我们的 cost-sensitive 的评估表明，尽管垃圾回收和准确率很高，但朴素贝叶斯过滤器在被阻止的消息被删除时，是不可行（我们建模的情况$ \lambda=999$ ）。 然而，有了额外的安全网，就像重新发送到私人地址一样，阻止合法消息的成本较低（我们使用过$ \lambda=1$ 和 $\lambda=9$） ，并且过滤器发挥着稳定且显著的作用。

我们计划实现基于不同的机器学习算法的反垃圾邮件过滤器，并与朴素贝叶斯过滤器比较。 我们希望自动反垃圾邮件过滤成为互联网垃圾过滤的新兴工具，其中包括广告删除工具（Kushmerick，1999），并敌意、色情材料屏蔽（Forsyth，1996; Spertus，1997）。


\begin{thebibliography}{99}
\bibitem{1}. Apte, C., and Damerau, F. Automated Learning of Decision Rules for Text Categorization. ACM Transactions on Information Systems, 12(3):233–251, 1994.
\bibitem{2}. Cohen, W.W. Learning Rules that Classify E-Mail. Proceedings of the AAAI Spring Symposium on Machine Learning in Information Access, Stanford, California, 1996.
\bibitem{3}. Cranor, L.F., and LaMacchia, B.A. Spam! Communications of ACM, 41(8):74–83, 1998.
\bibitem{4}. Dagan, I., Karov, Y., and Roth, D. Mistake-Driven Learning in Text Categorization. Proceedings of the 2nd Conference on Empirical Methods in Natural Language Processing, pages 55–63, Providence, Rhode Island, 1997.
\bibitem{5}. Domingos, P., and Pazzani, M. Beyond Independence: Conditions for the Optimality of the Simple Bayesian Classifier. Proceedings of the 13th Int. Conference on Machine Learning, pp. 105–112, Bari, Italy, 1996.
\bibitem{6}. Duda, R.O., and Hart, P.E. Bayes Decision Theory. Chapter 2 in Pattern Classification and Scene Analysis, pp. 10–43. John Wiley, 1973.
\bibitem{7}. Hall, R.J. How to Avoid Unwanted Email. Communications of ACM, 41(3):88–95, 1998.
\bibitem{8}. Kushmerick, N. Learning to Remove Internet Advertisements. Proceedings of the 3rd International Conference on Autonomous Agents, pp. 175–181, Seattle, Washington, 1999.
\bibitem{9}. Lang, K. Newsweeder: Learning to Filter Netnews. Proceedings of the 12th Int. Conference on Machine Learning, pp. 331–339, Stanford, California, 1995.
\bibitem{10}. Langley, P., Wayne, I., and Thompson, K.. An Analysis of Bayesian Classifiers. Proceedings of the 10th National Conference on AI, pp. 223–228, San Jose, California, 1992.
\bibitem{11}. Lewis, D. Feature Selection and Feature Extraction for Text Categorization. Proceedings of the DARPA Workshop on Speech and Natural Language, pp. 212–217, Harriman, New York, 1992.
\bibitem{12}. Lewis, D. Training Algorithms for Linear Text Classifiers. Proceedings of the 19th Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, pp. 298–306, Konstanz, Germany, 1996.
\bibitem{13}. Lewis, D. and Knowles, K.A. Threading Electronic Mail: A Preliminary Study. Information Processing and Management, 33(2):209–217, 1997.
\bibitem{14}. Mitchell, T.M. Machine Learning. McGraw-Hill, 1997.
\bibitem{15}. Payne, T.R. and Edwards, P. Interface Agents that Learn: An Investigation of Learning Issues in a Mail Agent Interface. Applied Artificial Intelligence, 11(1):1–32, 1997.
\bibitem{16}. Sahami, M., Dumais, S., Heckerman, D., and Horvitz, E. A Bayesian Approach to Filtering Junk EMail. In Learning for Text Categorization – Papers from the AAAI Workshop, pp. 55–62, Madison Wisconsin. AAAI Technical Report WS-98-05, 1998.
\bibitem{17}. Sebastiani, F. Machine Learning in Automated Text Categorisation. Technical Reeport B4-31, Istituto di Elaborazione dell'Informazione, Consiglio Nazionale delle Ricerche, Pisa, 1999. http://faure.iei.pi.cnr.it/~fabrizio.
\bibitem{18}. Spertus, E. Smokey: Automatic Recognition of Hostile Messages. Proceedings of the 14th National Conference on AI and the 9th Conference on Innovative Applications of AI, pp. 1058–1065, Providence, Rhode Island, 1997.
\end{thebibliography}
\end{document}	
